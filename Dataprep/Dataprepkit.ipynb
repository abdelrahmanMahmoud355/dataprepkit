{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m4\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# Importing essential data analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepKit:\n",
    "    \"\"\"\n",
    "    DataPrepKit - A class for data preparation tasks.\n",
    "\n",
    "    This class encapsulates functionality for common data preparation tasks, including reading data from various file formats.\n",
    "\n",
    "    Attributes:\n",
    "    - data (pd.DataFrame): The main data container.\n",
    "\n",
    "    Methods:\n",
    "    - __init__(self, data): Initializes the DataPrepKit instance with a provided DataFrame.\n",
    "    - read_data(self, file_path, file_format): Reads data from the specified file and updates the 'data' attribute.\n",
    "\n",
    "    Usage:\n",
    "    >>> prep_kit = DataPrepKit(data)\n",
    "    >>> prep_kit.read_data('example.csv', 'csv')\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initializes the DataPrepKit instance.\n",
    "\n",
    "        Parameters:\n",
    "        - data (pd.DataFrame): The initial DataFrame to work with.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def read_data(self, file_path, file_format):\n",
    "        \"\"\"\n",
    "        Reads data from a file and updates the 'data' attribute.\n",
    "\n",
    "        Parameters:\n",
    "        - file_path (str): The path to the data file.\n",
    "        - file_format (str): The format of the data file ('csv', 'excel', or 'json').\n",
    "\n",
    "        Usage:\n",
    "        >>> prep_kit.read_data('example.csv', 'csv')\n",
    "        \"\"\"\n",
    "        if file_format == 'csv':\n",
    "            self.data = pd.read_csv(file_path)\n",
    "        elif file_format == 'excel':\n",
    "            self.data = pd.read_excel(file_path)\n",
    "        elif file_format == 'json':\n",
    "            self.data = pd.read_json(file_path)\n",
    "        else:\n",
    "            print(\"Invalid file format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(self):\n",
    "    \"\"\"\n",
    "    Generate a summary of the data.\n",
    "\n",
    "    This method computes various statistical summaries and information about the DataFrame, providing insights into its structure and content.\n",
    "\n",
    "    Output:\n",
    "    - Average: Mean values for each column.\n",
    "    - Most frequent values: The mode of each column.\n",
    "    - Describe: Descriptive statistics (count, mean, std, min, 25%, 50%, 75%, max).\n",
    "    - Head: The first few rows of the DataFrame.\n",
    "    - Tail: The last few rows of the DataFrame.\n",
    "    - Info: A concise summary of the DataFrame's columns.\n",
    "    - Missing Values: The count of missing values in each column.\n",
    "    - Unique Values: The count of unique values in each column.\n",
    "\n",
    "    Usage:\n",
    "    >>> prep_kit = DataPrepKit(data)\n",
    "    >>> prep_kit.data_summary()\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Data Summary\")\n",
    "    print(\"==========================\")\n",
    "    summary = {\n",
    "        'Average': self.data.mean(),\n",
    "        'Most frequent values': self.data.mode().iloc[0],\n",
    "        'Describe': self.data.describe(),\n",
    "        'Head': self.data.head(),\n",
    "        'Tail': self.data.tail(),\n",
    "        'Info': self.data.info(),\n",
    "        'Missing Values': self.data.isnull().sum(),\n",
    "        'Unique Values': self.data.nunique()\n",
    "    }\n",
    "    for key, value in summary.items():\n",
    "        print(key)\n",
    "        print(\"===============\")\n",
    "        print(value)\n",
    "    print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(self):\n",
    "    \"\"\"\n",
    "    Remove duplicate rows from the DataFrame.\n",
    "\n",
    "    This method removes duplicate rows based on all columns, keeping the first occurrence of each duplicated row and modifying the DataFrame in place.\n",
    "\n",
    "    Usage:\n",
    "    >>> prep_kit = DataPrepKit(data)\n",
    "    >>> prep_kit.drop_duplicates()\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    self.data.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(data, handling_Type):\n",
    "    \"\"\"\n",
    "    Handle missing values in a DataFrame based on the specified strategy.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing missing values.\n",
    "    - handling_Type (str): The strategy for handling missing values ('mean', 'median', or 'drop').\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with missing values handled according to the specified strategy.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If an unsupported missing value handling strategy is provided.\n",
    "\n",
    "    Usage:\n",
    "    >>> cleaned_data = handle_missing_values(input_data, 'mean')\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    if handling_Type == 'mean':\n",
    "        return df.fillna(data.mean())\n",
    "    elif handling_Type == 'median':\n",
    "        return df.fillna(data.median())\n",
    "    elif handling_Type == 'drop':\n",
    "        return df.dropna()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported missing value handling strategy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_data(self):\n",
    "    \"\"\"\n",
    "    Encode categorical data in the DataFrame using one-hot encoding.\n",
    "\n",
    "    This method identifies columns with object (categorical) data types, applies one-hot encoding, and replaces the original DataFrame with the encoded version.\n",
    "\n",
    "    Usage:\n",
    "    >>> prep_kit = DataPrepKit(data)\n",
    "    >>> prep_kit.encode_categorical_data()\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    encoded_data = pd.get_dummies(\n",
    "        self.data, columns=self.data.select_dtypes(include='object').columns)\n",
    "    self.data = encoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12933f9724c962e3c6970c234a482e7d17d2b848e1d390ec0160a5236b8b248e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
